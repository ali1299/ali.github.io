<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<html>
  <head>
  <link rel="stylesheet" href="main.css">
  <link rel="icon" type="image/ico" href="favicon.ico">

	  <!-- Global site tag (gtag.js) - Google Analytics -->
	<script async src="https://www.googletagmanager.com/gtag/js?id=UA-112406581-2"></script>
	<script>
	  window.dataLayer = window.dataLayer || [];
	  function gtag(){dataLayer.push(arguments);}
	  gtag('js', new Date());

	  gtag('config', 'UA-112406581-2');
	</script>

  <title>Amlaan Bhoi</title>
  </head>
  <body>
  <table width="800" border="0" align="center" cellspacing="0" cellpadding="0">
    <tr>
    <td>
      <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
      <tr>
        <td width="67%" valign="middle">
        <p align="center">
          <name>Amlaan Bhoi</name>
        </p>
        <p align="justify">I am a graduate student in Computer Science at <a href="https://www.uic.edu/">University of Illinois at Chicago</a> where I'm working on action recognition. I expect to graduate in May 2019. My advisor is <a href="https://www.cs.uic.edu/~zhangx/">Xinhua Zhang</a>. I am currently interning as a R&D Intern at <a href="https://www.cccis.com/">CCC Information Services</a> where I work in the Machine Learning/Photo Analytics team. I am also an <a href="https://software.intel.com/en-us/ai-academy/ambassadors">Intel AI Student Ambassador</a> through which I share upcoming research on Artificial Intelligence, Machine Learning, & Deep Learning. I graduated from <a href="http://www.amity.edu/">Amity University</a> with a B.Tech in Computer Science & Engineering in May 2017 with First Class honors where I was advised by <a href="https://www.nitw.ac.in/faculty/id/16877/">Sushil Kumar</a>. 
        </p>

        <p align="justify">I love reading machine learning papers on <a href="http://www.arxiv-sanity.com/">Arxiv Sanity</a> and am always keen on learning something new! I also work on iOS development and Apple's ARKit to develop augmented reality experiences.
        </p>
        <p align=center>
          <a href="mailto:abhoi3@uic.edu">E-mail</a> &nbsp|&nbsp
          <a href="cv/cv.pdf">CV</a> &nbsp|&nbsp
          <!-- <a href="JonBarron-bio.txt">Blog</a> &nbsp|&nbsp -->
          <a href="https://scholar.google.com/citations?user=6zkTbN4AAAAJ&hl=en">Google Scholar</a>
          &nbsp|&nbsp
          <a href="http://www.linkedin.com/in/abhoi/"> LinkedIn </a> &nbsp|&nbsp
          <a href="https://github.com/abhoi"> Github </a> &nbsp|&nbsp
<!--           <a href="https://www.facebook.com/amlaanb"> Facebook </a> &nbsp|&nbsp -->
          <a href="https://www.twitter.com/amlaanb"> Twitter </a> &nbsp|&nbsp
	  <a href="https://abhoi.github.io/blog/"> Blog </a>
        </p>
        </td>
        <td width="33%">
        <img class="profile-pic" src="images/profile_pic.jpg">
        <center>
        <img src="images/logos.png" width=100%>
        </center>
        </td>
      </tr>
      </table>
      
      <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
      <tr>
        <td width="100%" valign="middle">
          <heading>Research Interests</heading>
          <p align="justify">
          I'm interested in computer vision, image processing, machine learning, statistical machine learning, optimization, augmented reality, and computational photography. I've worked on spatio-temporal action recognition, monocular depth esimation, instance segmentation, and fast semantic segmentation. My Master's thesis was on <b>Invariant Kernels for Few-shot Learning</b> where we extend orbit embeddings to convolutional neural networks in the domain of few-shot learning.
          </p>
        </td>
      </tr>
      </table>

<table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
  <tr>
    <td>
    	<heading>News</heading>
    	<ul>
		    <li><strong>[Dec 2018]</strong> Continuing my internship at CCC Information Services for the Fall 2018, Winter 2018, and Spring 2019 semester.</li>
    		<li><strong>[Aug 2018]</strong> Featured on Intel's website discussing my work, computer vision problems, and how Intel can help. Check it out <strong><a href="https://software.intel.com/en-us/blogs/2018/08/03/ai-student-ambassador-amlaan-bhoi-solving-computer-vision-problems-through-machine">here</a></strong>!</li>
    		<li><strong>[Jun 2018]</strong> Presented poster on <a href="https://www.dropbox.com/s/4329409ls1t5m2i/DenseNet-poster.pdf?dl=0"><i>Tiramisu DenseNet Architecture for Precise Segmentation</i></a> at Intel AI Booth at <a href="https://www.linkedin.com/feed/update/urn:li:activity:6415319016641949696/">CVPR 2018</a>.</li>
    		<li><strong>[May 2018]</strong> Joined as an Intern, R&D in the Photo Analytics and Machine Learning group at CCC Information Services.</li>
    		<li><strong>[Apr 2018]</strong> Joined Intel AI Ambassador Program.</li>
    		<li><strong>[Jan 2018]</strong> Mentioned in <a href="https://news.ucsc.edu/2018/01/cruzhacks.html">UCSC newsletter</a> for developing a low-poly VR application (Google Pixel 2 + DayDream) at CruzHacks 2017.</li>
    		<li><strong>[Oct 2017]</strong> Awarded <a href="https://devpost.com/software/lifeguard-io"><strong>Best Microsoft Hack</strong></a> at HackHarvard 2017.</li>
    		<li><strong>[May 2017]</strong> Awarded <strong>Best Technical Innovation</strong> at Amity University Convocation 2017.</li>
    	</ul>
    </td>
  </tr>
  </table>

  <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
  <tr>
    <td>
    <heading>Papers</heading>
    </td>
  </tr>
  </table>

  <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
    <tr onmouseout="style_stop()" onmouseover="style_start()" >
      <td width="25%">
        <div class="one">
        <div class="two" id = 'style_image'><img class="portrait_image" src='papers/style/after.png'></div>
        <img class="portrait_image" src='papers/style/before.png'>
        </div>
        <script type="text/javascript">
        function style_start() {
        document.getElementById('style_image').style.opacity = "1";
        }
        function style_stop() {
        document.getElementById('style_image').style.opacity = "0";
        }
        style_stop()
        </script>
      </td>
      <td valign="top" width="75%">
	  <a href="https://arxiv.org/abs/1806.00868">
            <papertitle>A Comprehensive Comparison between Neural Style Transfer and Universal Style Transfer</papertitle>
	  </a>
	  <br>
          <a href="https://github.com/titu1994">Somshubra Majumdar</a>,
          <strong>Amlaan Bhoi</strong>,
          <a href="https://www.linkedin.com/in/ganeshjcs">Ganesh Jagadeesan</a>
      <br>
        <em>arXiv Preprint</em>, 2018 <br>
        <a href="https://arxiv.org/abs/1806.00868">arxiv</a>
        |
        <a href="https://github.com/titu1994/Neural-Style-Transfer">code</a>
        <p align="justify">Style transfer aims to transfer arbitrary visual styles to content images. We explore algorithms adapted from two papers that try to solve the problem of style transfer while generalizing on unseen styles or compromised visual quality. Majority of the improvements made focus on optimizing the algorithm for real-time style transfer while adapting to new styles with considerably less resources and constraints. We compare these strategies and compare how they measure up to produce visually appealing images. We explore two approaches to style transfer: <i>neural style transfer with improvements</i> and <i>universal style transfer</i>. We also make a comparison between the different images produced and how they can be qualitatively measured.</p>
      </td>
    </tr>
    <tr>
      <td width="25%"><img src="papers/absa/before.png" alt="3DSP" width="160" height="120" style="border-style: none">
      <td valign="top" width="75%">
	  <a href="https://arxiv.org/abs/1805.01984">
            <papertitle>Various Approaches to Aspect-based Sentiment Analysis</papertitle>
	  </a>
	  <br>
          <strong>Amlaan Bhoi</strong>,
          <a href="https://sandeepjoshi1910.github.io/">Sandeep Joshi</a>
      <br>
        <em>arXiv Preprint</em>, 2018 <br>
        <a href="https://arxiv.org/abs/1805.01984">arxiv</a>
	|
	<a href="https://github.com/abhoi/memnet-absa">code</a>
        <p align="justify">The problem of aspect-based sentiment analysis deals with classifying sentiments (negative, neutral, positive) for a given aspect in a sentence. A traditional sentiment classification task involves treating the entire sentence as a text document and classifying sentiments based on all the words. Let us assume, we have a sentence such as "the <i>acceleration</i> of this car is fast, but the <i>reliability</i> is horrible". This can be a difficult sentence because it has two aspects with conflicting sentiments about the same entity. Considering machine learning techniques (or deep learning), how do we encode the information that we are interested in one aspect and its sentiment but not the other? Let us explore various pre-processing steps, features, and methods used to facilitate in solving this task.</p>
      </td>
    </tr>
</table>

  <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
  <tr>
    <td>
    <heading>Projects</heading>
    </td>
  </tr>
  </table>

  <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
      <tr onmouseout="iris_stop()" onmouseover="iris_start()" >
          <td width="25%">
            <div class="one">
            <div class="two" id = 'iris_image'><img class="portrait_image" src='projects/iris/after.gif'></div>
            <img class="portrait_image" src='projects/iris/after.gif'>
            </div>
            <script type="text/javascript">
            function iris_start() {
            document.getElementById('iris_image').style.opacity = "1";
            }
            function iris_stop() {
            document.getElementById('iris_image').style.opacity = "0";
            }
            ocr_stop()
            </script>
          </td>
          <td valign="top" width="75%">
        <a href="https://github.com/titu1994/Advanced_Machine_Learning">
                <papertitle>Iris: Speech to Code Converter</papertitle>
        </a>
        <br>
            <strong>Amlaan Bhoi</strong>,
              <a href="https://www.linkedin.com/in/shubadra-govindan/">Shubadra Govindan</a>,
              <a href="https://sandeepjoshi1910.github.io/">Sandeep Joshi</a>,
              <a href="https://dkaushik94.github.io">Debojit Kaushik</a>
          <br>
            <em>HackHarvard, 2018</em><br>
            <a href="https://devpost.com/software/iris-1f36ns">devpost</a>
            |
            <a href="https://github.com/abhoi/Speech2Code/">code</a>
            <p align="justify">A semantic speech to code generator.</p>
            <ul>
            <li>Trained an intent classification model in Microsoft LUIS to recognize 15+ commands.</li>
            <li>Implemented a message passing protocol using RabbitMQ to talk between backend scripts, ElectronJS, and Visual Code extension.</li>
            <li>Wrote Python API wrappers for Microsoft LUIS and Google Cloud Speech API.</li>
        </ul>
          </td>
        </tr>

    <tr onmouseout="ocr_stop()" onmouseover="ocr_start()" >
      <td width="25%">
        <div class="one">
        <div class="two" id = 'ocr_image'><img class="portrait_image" src='projects/ocr/after.png'></div>
        <img class="portrait_image" src='projects/ocr/before.png'>
        </div>
        <script type="text/javascript">
        function ocr_start() {
        document.getElementById('ocr_image').style.opacity = "1";
        }
        function ocr_stop() {
        document.getElementById('ocr_image').style.opacity = "0";
        }
        ocr_stop()
        </script>
      </td>
      <td valign="top" width="75%">
	  <a href="https://github.com/titu1994/Advanced_Machine_Learning">
            <papertitle>Conditional Random Fields for Structured Output Prediction</papertitle>
	  </a>
	  <br>
	  	  <strong>Amlaan Bhoi</strong>,
          <a href="https://github.com/titu1994">Somshubra Majumdar</a>,
          <a href="https://www.linkedin.com/in/ganeshjcs">Ganesh Jagadeesan</a>
      <br>
        <em>Advanced Machine Learning</em>, Spring 2018 <br>
        <a href="https://github.com/titu1994/Advanced_Machine_Learning">code</a>
        |
        <a href="https://github.com/titu1994/Advanced_Machine_Learning/blob/master/Project2-PETSc/Latex/Project_2.pdf">report</a>
        <p align="justify">An optical character recognition system to detect letters and words using conditional random fields.</p>
        <ul>
  			<li>Implemented linear-chain Conditional Random Fields from scratch to detect characters on UPenn OCR dataset.</li>
  			<li>Implemented the Viterbi algorithm for forward-backward message passing between nodes, calculated the log probabilities and gradients, and used LBFGS solver to reach convergence.</li>
  			<li>Achieved 84% letter-wise accuracy with dynamic programming implementation.</li>
  			<li>Wrote a PETSc/Tao version to run on <a href="https://acer.uic.edu/">ACER</a> cluster in parallel using MPI code.</li>
  			<li>Implemented SGD with Nestorov Momentum, AMSGrad, and Adam with MCMC for CRFs to compare with LBFGS implementation and plot comparison charts on different &#955 values.</li>
		</ul>
      </td>
    </tr>

        <tr onmouseout="friendly_stop()" onmouseover="friendly_start()" >
      <td width="25%">
        <div class="one">
        <div class="two" id = 'friendly_image'><img class="portrait_image" src='projects/apriori/after.png'></div>
        <img class="portrait_image" src='projects/apriori/before.png'>
        </div>
        <script type="text/javascript">
        function friendly_start() {
        document.getElementById('friendly_image').style.opacity = "1";
        }
        function friendly_stop() {
        document.getElementById('friendly_image').style.opacity = "0";
        }
        friendly_stop()
        </script>
      </td>
      <td valign="top" width="75%">
        <p><a href="https://github.com/abhoi/ms-apriori">
        <papertitle>MS Apriori: Rule Mining with Multiple Minimum Supports</papertitle></a><br>
        <strong>Amlaan Bhoi</strong>, <a href="https://sandeepjoshi1910.github.io/">Sandeep Joshi</a>
        <br>
        <em>Data Mining & Text Mining</em>, Spring 2018 <br>
        <a href="https://github.com/abhoi/ms-apriori">code</a>
        <p></p>
        <p align="justify">An association rule mining (unsupervised learning) algorithm with multiple minimum support. This algorithm can be used for product recommendations based on historical data.</p>
      </td>
    </tr>

    <tr onmouseout="aperture_stop()" onmouseover="aperture_start()" >
      <td width="25%">
        <div class="one">
        <div class="two" id = 'aperture_image'><img class="portrait_image" src='projects/alethea/after.png'></div>
        <img class="portrait_image" src='projects/alethea/after.png'>
        </div>
        <script type="text/javascript">
        function aperture_start() {
        document.getElementById('aperture_image').style.opacity = "1";
        }
        function aperture_stop() {
        document.getElementById('aperture_image').style.opacity = "0";
        }
        aperture_stop()
        </script>
      </td>
      <td valign="top" width="75%">
	  <a href="https://dkaushik94.github.io/vis-alethea/">
            <papertitle>Alethea: Data science, visualization, and analysis</papertitle>
	  </a>
	  <br>
	  <a href="https://github.com/titu1994">Somshubra Majumdar</a>,
      <strong>Amlaan Bhoi</strong>,
	  <a href="https://github.com/dkaushik94">Debojit Kaushik</a>,
	  <a href="https://github.com/calphones">Christopher Alphones</a>
	  <br>
        <em>Introduction to Data Science</em>, Spring 2018 <br>
        <a href="https://github.com/dkaushik94/vis-alethea">code</a>
        |
        <a href="https://dkaushik94.github.io/vis-alethea/">demo</a>
        <p></p>
        <p align="justify">An ETL pipeline, visualization, classical ML prediction, and ML&DL sentiment analysis application on publicly available <a href="https://data.cityofchicago.org/">Chicago</a> and <a href="https://www.yelp.com/developers">Yelp</a> data.</p>
        <ul>
  			<li>Performed data discovery, integration, and visualization on <a href="https://data.cityofchicago.org/">Chicago</a> datasets using Pandas, Numpy, and React Recharts.</li>
  			<li>Achieved 81.9% sentiment analysis accuracy using Multiplicative LSTMs on Yelp Reviews dataset.</li>
  			<li>Achieved 91.3% accuracy predicting types of robberies occuring in Chicago for the Summer of 2018 based on previous crime and weather datasets.</li>
		</ul>
      </td>
    </tr>
		
    <tr onmouseout="deepburst_stop()" onmouseover="deepburst_start()" >
      <td width="25%">
        <div class="one">
        <div class="two" id = 'deepburst_image'><img class="portrait_image" src='projects/lifeguard/after.png'></div>
        <img class="portrait_image" src='projects/lifeguard/before.png'>
        </div>
        <script type="text/javascript">
        function deepburst_start() {
        document.getElementById('deepburst_image').style.opacity = "1";
        }
        function deepburst_stop() {
        document.getElementById('deepburst_image').style.opacity = "0";
        }
        deepburst_stop()
        </script>
      </td>
      <td valign="top" width="75%">
        <a href="https://devpost.com/software/lifeguard-io">
        <papertitle>Lifeguard: Action Recognition of Drowning while Swimming</papertitle>
        </a>
        <br>
        <a href="https://devpost.com/sswarnakar">Sudipta Swarnakar</a>,
        <strong>Amlaan Bhoi</strong>,
        <a href="https://devpost.com/ChetanVelivela">Chetan Velivela</a>
        <br>
        <em>HackHarvard</em>, 2017<!--   &nbsp <font color=#FF8080><strong>(Spotlight)</strong></font>  --><br>
        <a href ="https://devpost.com/software/lifeguard-io">devpost</a>
        <p align="justify">We trained a 3D Convolutional Neural Network model on Microsoft Azure to detect drowning people in swimming pools. We also created the bounding boxes for our train, test, and validation set.</p>
      </td>
    </tr>

    <tr onmouseout="hdrnet_stop()" onmouseover="hdrnet_start()" >
      <td width="25%">
        <div class="one">
        <div class="two" id = 'hdrnet_image'><img class="portrait_image" src='projects/ar/after.png'></div>
        <img class="portrait_image" src='projects/ar/before.png'>
        </div>
        <script type="text/javascript">
        function hdrnet_start() {
        document.getElementById('hdrnet_image').style.opacity = "1";
        }
        function hdrnet_stop() {
        document.getElementById('hdrnet_image').style.opacity = "0";
        }
        hdrnet_stop()
        </script>
      </td>
      <td valign="top" width="75%">
        <p><a href="https://github.com/dkaushik94/ARyouthereyet">
        <papertitle>ARYouThereYet</papertitle></a><br>
        <a href="https://sandeepjoshi1910.github.io/">Sandeep Joshi</a>, <strong>Amlaan Bhoi</strong>, <a href="https://github.com/dkaushik94">Debojit Kaushik</a> 
        <br>
        <em>Virtual and Augmented Reality</em>, Fall 2017 <br>
        <a href="https://debojitkaushikblog.wordpress.com/finally-some-augmented-reality-aryouthereyet/">project page</a>
        |
        <a href="https://github.com/dkaushik94/ARyouthereyet">code</a>
        |
        <a href="https://www.youtube.com/watch?v=U6ChLMEDQh0&t=5s">video</a>
        <p></p>
        <p align="justify">An ARKit iOS application utilizing Google Maps and Mapbox APIs to show nearby attractions in Augmented Reality with support for visualizing the distance, detailed description of places, an AR walking guide to destinations, support for saving favorite places, and more.</p>
      </td>
    </tr>

    <tr onmouseout="ffcc_stop()" onmouseover="ffcc_start()" >
      <td width="25%">
        <div class="one">
        <div class="two" id = 'ffcc_image'><img class="portrait_image" src='projects/autocolor/after.png'></div>
        <img class="portrait_image" src='projects/autocolor/before.png'>
        </div>
        <script type="text/javascript">
        function ffcc_start() {
        document.getElementById('ffcc_image').style.opacity = "1";
        }
        function ffcc_stop() {
        document.getElementById('ffcc_image').style.opacity = "0";
        }
        ffcc_stop()
        </script>
      </td>
      <td valign="top" width="75%">
	<p><a href="https://github.com/abhoi/AutoColor"></p>
        <papertitle>Autocolor: Color Segmentation using Clustering</papertitle></a><br>
        <strong>Amlaan Bhoi</strong>
        <em>Summer</em>, 2017 <br>
        <a href ="https://github.com/abhoi/AutoColor">code</a>
        <p></p>
        <p align="justify">A K-means clustering algorithm using <a href="https://opencv.org/">OpenCV</a> and <a href="http://scikit-learn.org/stable/">Scikit-Learn</a> that detects K dominant colors in an image. Autopicks K using <a href="http://scikit-learn.org/stable/modules/generated/sklearn.metrics.silhouette_score.html">Silhouette Coefficient</a> metric and <a href="http://scikit-learn.org/stable/modules/generated/sklearn.cluster.MiniBatchKMeans.html">MiniBatchKMeans</a> for testing.</p>
      </td>
    </tr>
</table>
      <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
      <tr>
        <td>
        <br>
        <hr>
        <p align="center">
        	<quote>"If we want machines to think, we need to teach them to see" ~ Fei-Fei Li</quote>
        	</br> 
        	<font>Design stolen from <a href="https://jonbarron.info/">here</a></font>
        </p>
        </td>
      </tr>
      </table>
    </td>
    </tr>
  </table>
  </body>
</html>
